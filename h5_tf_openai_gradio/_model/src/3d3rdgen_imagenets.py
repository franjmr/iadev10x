# -*- coding: utf-8 -*-
"""3D3RDGEN_IMAGENETS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wadsvzst9ghtWQNZWQCcnJMpanE2-6gp

### Notebook de prueba en Colab

Este es un notebook de prueba en Google Colab.
"""

import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import requests
import tensorflow as tf
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from PIL import Image
import numpy as np
from io import BytesIO
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
import time

BASE_URL = "https://www.vgamuseum.info/index.php/cards"

def fetch_html_vgamuseum(url):
    """Descarga y devuelve el HTML de una URL del sitio vgamuseum.info"""
    try:
        r = requests.get(url, timeout=10)
        r.raise_for_status()
        return r.text
    except Exception as e:
        print(f"‚ùå Error al acceder a {url}: {e}")
        return None


def extract_category_links_vgamuseum(base_url):
    """Extrae todos los enlaces a categor√≠as principales desde /cards"""
    html = fetch_html_vgamuseum(base_url)
    if not html:
        return []

    soup = BeautifulSoup(html, "html.parser")
    fulltext_div = soup.find("div", class_="itemFullText")
    if not fulltext_div:
        print("‚ö†Ô∏è No se encontr√≥ div.itemFullText en la p√°gina principal.")
        return []

    category_links = []
    for li in fulltext_div.find_all("li"):
        a_tag = li.find("a", href=True)
        if a_tag:
            full_url = urljoin(base_url, a_tag["href"])
            category_links.append(full_url)
    print(f"üîó Encontradas {len(category_links)} categor√≠as.")
    return category_links


def extract_subcategory_links_vgamuseum(category_url):
    """
    Extrae las subp√°ginas de tarjetas (por modelo o serie) dentro de una categor√≠a,
    gestionando la paginaci√≥n localizada en 'ul.pagination-list a.pagenav'.
    """
    html = fetch_html_vgamuseum(category_url)
    if not html:
        return []

    soup = BeautifulSoup(html, "html.parser")

    # 1Ô∏è‚É£ Obtener todas las URLs de paginaci√≥n (incluyendo la p√°gina inicial)
    pagination_urls = [category_url]
    pagination_section = soup.select("ul.pagination-list a.pagenav")

    for a_tag in pagination_section:
        page_url = urljoin(category_url, a_tag["href"])
        if page_url not in pagination_urls:
            pagination_urls.append(page_url)

    print(f"  üìÅ {len(pagination_urls)} p√°ginas de subcategor√≠as encontradas en {category_url}")

    # 2Ô∏è‚É£ Iterar por todas las p√°ginas (original + paginadas) y extraer subp√°ginas
    sub_links = []
    for page_url in pagination_urls:
        html_page = fetch_html_vgamuseum(page_url)
        if not html_page:
            continue

        soup_page = BeautifulSoup(html_page, "html.parser")

        for h3 in soup_page.find_all("h3", class_="catItemTitle"):
            a_tag = h3.find("a", href=True)
            if a_tag:
                full_url = urljoin(page_url, a_tag["href"])
                sub_links.append(full_url)

    print(f"  üìÅ {len(sub_links)} subcategor√≠as encontradas en {category_url} (paginaci√≥n incluida)")
    return sub_links


def extract_images_from_subpage_vgamuseum(sub_url):
    """
    Extrae todas las im√°genes JPG dentro de div.itemFullText,
    descarta las que contengan 'driv' y devuelve tambi√©n el t√≠tulo
    (h2.itemTitle dentro de div.itemHeader).
    """
    html = fetch_html_vgamuseum(sub_url)
    if not html:
        return []

    soup = BeautifulSoup(html, "html.parser")

    # üîπ Obtener el t√≠tulo de la subp√°gina
    title = None
    header_div = soup.find("div", class_="itemHeader")
    if header_div:
        title_tag = header_div.find("h2", class_="itemTitle")
        if title_tag:
            title = title_tag.get_text(strip=True)

    fulltext_divs = soup.find_all("div", class_="itemFullText")
    images = []

    for div in fulltext_divs:
        for a_tag in div.find_all("a", href=True):
            href = a_tag["href"]
            if href.lower().endswith(".jpg"):
                img_url = urljoin(sub_url, href)

                # Descartar im√°genes relacionadas con drivers
                if "driv" in img_url.lower() or "drv" in img_url.lower() or "driver" in img_url.lower():
                    print(f"    ‚ö†Ô∏è Descartada imagen de drivers: {img_url}")
                    continue

                images.append({
                    "title": title or "Sin t√≠tulo",
                    "image_url": img_url
                })

    if images:
        print(f"    üñºÔ∏è {len(images)} im√°genes v√°lidas encontradas en {sub_url} ‚Äî {title or 'Sin t√≠tulo'}")
    return images


def scrape_vgamuseum_cards(base_url):
    """Scraper principal para recorrer todo el √°rbol de categor√≠as y subcategor√≠as con paginaci√≥n"""
    all_data = []

    categories = extract_category_links_vgamuseum(base_url)

    print(f"\nüîé Recuperadas {len(categories)} categor√≠as principales.")

    included_categories = [
        "https://www.vgamuseum.info/index.php/cards/itemlist/category/31-s3-graphics",
        "https://www.vgamuseum.info/index.php/cards/itemlist/category/2-3dfx",
        "https://www.vgamuseum.info/index.php/cards/itemlist/category/22-matrox",
        "https://www.vgamuseum.info/index.php/cards/itemlist/category/9-ati-technologies-inc",
        "https://www.vgamuseum.info/index.php/cards/itemlist/category/27-nvidia-corporation",
        "https://www.vgamuseum.info/index.php/cards/itemlist/category/39-trident-microsystems-inc"
    ]

    for cat_url in categories:
        if cat_url not in included_categories:
            continue

        sub_links = extract_subcategory_links_vgamuseum(cat_url)
        for sub_url in sub_links:
            images = extract_images_from_subpage_vgamuseum(sub_url)

            category_from_url = cat_url.split("/")[-1]
            category = "-".join(category_from_url.split("-")[1:])

            for img_info in images:
                all_data.append({
                    "category": category,
                    "category_url": cat_url,
                    "subpage_url": sub_url,
                    "title": img_info["title"],
                    "image_url": img_info["image_url"]
                })
            time.sleep(1)  # evita sobrecargar el servidor

    return all_data


# Ejecutar el scraping completo (sin guardar CSV)
cards = scrape_vgamuseum_cards(BASE_URL)

print(f"\n‚úÖ Total de im√°genes encontradas: {len(cards)}")
print("Ejemplo de resultados en memoria:")
for c in cards[:20]:
    print(f"- {c['category']} - {c['title']} - {c['image_url']}")

def download_images_as_binary(cards):
    """
    Dada una lista de diccionarios con 'title' y 'url',
    descarga cada imagen y devuelve una lista con (title, img_binary).
    """
    downloaded = []

    for card in cards:
        category = card.get("category")
        url = card.get("image_url")

        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            img_binary = BytesIO(response.content)
            downloaded.append((category, img_binary))
            print(f"Descargada: {category} ({url})")

        except Exception as e:
            print(f"‚ö†Ô∏è No se pudo descargar {url}: {e}")

    return downloaded

binary_cards = download_images_as_binary(cards)
print(f"Total tarjetas descargadas: {len(binary_cards)}")

def get_image_size_stats(binary_images):
    """
    Calcula el tama√±o m√≠nimo y m√°ximo (ancho y alto) de una lista de im√°genes.
    binary_images: lista de tuplas (title, img_binary)
    """
    widths, heights = [], []

    for category, img_binary in binary_images:
        try:
            with Image.open(img_binary) as img:
                w, h = img.size
                widths.append(w)
                heights.append(h)
        except Exception as e:
            print(f"‚ö†Ô∏è No se pudo abrir imagen '{category}': {e}")

    if not widths or not heights:
        print("‚ùå No se pudo calcular tama√±os.")
        return None

    stats = {
        "min_width": min(widths),
        "max_width": max(widths),
        "min_height": min(heights),
        "max_height": max(heights),
        "count": len(widths)
    }

    print(f"üìä Total im√°genes analizadas: {stats['count']}")
    print(f"üìè Ancho -> min: {stats['min_width']}, max: {stats['max_width']}")
    print(f"üìê Alto  -> min: {stats['min_height']}, max: {stats['max_height']}")

    return stats

stats = get_image_size_stats(binary_cards)

import matplotlib.pyplot as plt
from collections import Counter

# binary_images: lista de tuplas (categoria, img_binary)
categories = [cat for cat, img in binary_cards]

# Contar cu√°ntas im√°genes hay por categor√≠a
counter = Counter(categories)

# Preparar datos para la gr√°fica
cats = list(counter.keys())
counts = list(counter.values())

# Graficar
plt.figure(figsize=(12, 6))
plt.bar(cats, counts, color='skyblue')
plt.xticks(rotation=90)
plt.ylabel("N√∫mero de im√°genes")
plt.xlabel("Categor√≠a")
plt.title("Distribuci√≥n de im√°genes por categor√≠a")
plt.show()

from google.colab import drive

"""guardar en google drive"""
drive.mount('/content/drive')

# Guardar en Drive
import pickle
with open("/content/drive/MyDrive/binary_cards.pkl", "wb") as f:
    pickle.dump(binary_cards, f)

from google.colab import drive
import pickle

# Montar Google Drive
drive.mount('/content/drive')

# Cargar el objeto pickle
file_path = "/content/drive/MyDrive/binary_cards.pkl"
with open(file_path, "rb") as f:
    binary_cards = pickle.load(f)

print(f"‚úÖ Recuperadas {len(binary_cards)} im√°genes y etiquetas.")

import matplotlib.pyplot as plt
from collections import Counter

# binary_images: lista de tuplas (categoria, img_binary)
categories = [cat for cat, img in binary_cards]

# Contar cu√°ntas im√°genes hay por categor√≠a
counter = Counter(categories)

# Preparar datos para la gr√°fica
cats = list(counter.keys())
counts = list(counter.values())

# Graficar
plt.figure(figsize=(12, 6))
plt.bar(cats, counts, color='skyblue')
plt.xticks(rotation=90)
plt.ylabel("N√∫mero de im√°genes")
plt.xlabel("Categor√≠a")
plt.title("Distribuci√≥n de im√°genes por categor√≠a")
plt.show()

# Bloque listo para Colab: resize seguro de im√°genes a 224x224 y salida en bytes (JPEG)
import io
from PIL import Image
from tqdm import tqdm  # opcional para progreso, instala con `pip install tqdm` si falta

def resize_image_bytes(img_input, size=(224, 224), jpeg_quality=90):
    """
    Recibe img_input (bytes o io.BytesIO), convierte a RGB, redimensiona y devuelve bytes JPEG.
    size: (width, height)
    jpeg_quality: calidad JPEG (0-100)
    """
    # Acepta bytes o BytesIO
    if isinstance(img_input, io.BytesIO):
        buf = img_input
    elif isinstance(img_input, (bytes, bytearray)):
        buf = io.BytesIO(img_input)
    else:
        raise TypeError(f"Tipo de imagen no soportado: {type(img_input)}")

    # Abrir y procesar
    with Image.open(buf) as img:
        img = img.convert("RGB")            # asegurar 3 canales
        img = img.resize(size, Image.LANCZOS)  # redimensionar con buen interpolador

        out_buf = io.BytesIO()
        img.save(out_buf, format="JPEG", quality=jpeg_quality)
        return out_buf.getvalue()


# Ejemplo: procesar toda la lista binary_images => resized_binary_images
# binary_images es: [(category, img_bytes), ...]
def resize_all_binary_images(binary_images, size=(224,224), jpeg_quality=90, show_progress=True):
    """
    Recorre binary_images y devuelve nueva lista con im√°genes redimensionadas.
    Procesa secuencialmente para no subir mucho la memoria.
    """
    resized = []
    iterator = tqdm(binary_images) if show_progress else binary_images

    for category, img_bin in iterator:
        try:
            new_bytes = resize_image_bytes(img_bin, size=size, jpeg_quality=jpeg_quality)
            resized.append((category, new_bytes))
        except Exception as e:
            # Si falla una imagen, la omitimos y avisamos
            print(f"‚ö†Ô∏è Error resize '{category}': {e}")
            # opcional: seguir o a√±adir un placeholder; aqu√≠ la omitimos
            continue

    return resized


# -----------------------
# Uso:
# -----------------------
# Suponiendo que ya tienes binary_images cargado en memoria
binary_cards = resize_all_binary_images(binary_cards, size=(224,224), jpeg_quality=90)
print(f"‚úÖ Redimensionadas {len(binary_cards)} im√°genes.")

import matplotlib.pyplot as plt
from collections import Counter

# binary_images: lista de tuplas (categoria, img_binary)
categories = [cat for cat, img in binary_cards]

# Contar cu√°ntas im√°genes hay por categor√≠a
counter = Counter(categories)

# Preparar datos para la gr√°fica
cats = list(counter.keys())
counts = list(counter.values())

# Graficar
plt.figure(figsize=(12, 6))
plt.bar(cats, counts, color='skyblue')
plt.xticks(rotation=90)
plt.ylabel("N√∫mero de im√°genes")
plt.xlabel("Categor√≠a")
plt.title("Distribuci√≥n de im√°genes por categor√≠a")
plt.show()

import io
import numpy as np
from PIL import Image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from collections import Counter
from tqdm import tqdm

def augment_minority_classes(binary_images, target_count=1600, size=(224, 224)):
    """
    Aumenta las clases minoritarias hasta alcanzar 'target_count' im√°genes.
    Usa ImageDataGenerator para generar nuevas muestras sint√©ticas.
    """
    # Contar cu√°ntas im√°genes tiene cada categor√≠a
    category_counts = Counter([cat for cat, _ in binary_images])
    print(f"üîç Distribuci√≥n original: {category_counts}")

    # Configurar Data Augmentation
    datagen = ImageDataGenerator(
        rotation_range=20,
        width_shift_range=0.1,
        height_shift_range=0.1,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest'
    )

    # Agrupar im√°genes por categor√≠a
    grouped = {}
    for category, img_bytes in binary_images:
        grouped.setdefault(category, []).append(img_bytes)

    augmented_images = []
    for category, imgs in tqdm(grouped.items(), desc="üîÑ Aumentando clases"):
        count = len(imgs)
        augmented_images.extend([(category, img) for img in imgs])  # im√°genes originales

        if count < target_count:
            needed = target_count - count
            print(f"üß© {category}: {count} ‚Üí {target_count} (a√±adiendo {needed})")

            # Convertir im√°genes a arrays
            img_arrays = []
            for img_bytes in imgs:
                with Image.open(io.BytesIO(img_bytes)) as img:
                    img = img.convert('RGB').resize(size)
                    img_arrays.append(np.array(img))

            img_arrays = np.array(img_arrays)
            img_arrays = img_arrays / 255.0  # normalizaci√≥n temporal

            # Generar im√°genes nuevas
            gen = datagen.flow(img_arrays, batch_size=1)

            for _ in range(needed):
                augmented = next(gen)[0]
                augmented = (augmented * 255).astype(np.uint8)
                img = Image.fromarray(augmented)
                buf = io.BytesIO()
                img.save(buf, format='JPEG', quality=90)
                augmented_images.append((category, buf.getvalue()))

    print(f"‚úÖ Total im√°genes tras aumento: {len(augmented_images)}")
    return augmented_images

binary_cards = augment_minority_classes(binary_cards, target_count=1600)

import matplotlib.pyplot as plt
from collections import Counter

# binary_images: lista de tuplas (categoria, img_binary)
categories = [cat for cat, img in binary_cards]

# Contar cu√°ntas im√°genes hay por categor√≠a
counter = Counter(categories)

# Preparar datos para la gr√°fica
cats = list(counter.keys())
counts = list(counter.values())

# Graficar
plt.figure(figsize=(12, 6))
plt.bar(cats, counts, color='skyblue')
plt.xticks(rotation=90)
plt.ylabel("N√∫mero de im√°genes")
plt.xlabel("Categor√≠a")
plt.title("Distribuci√≥n de im√°genes por categor√≠a")
plt.show()

import io
import random
import matplotlib.pyplot as plt
from PIL import Image

def show_examples_per_category(binary_images, examples_per_category=6, size=(224,224)):
    """
    Muestra una cuadr√≠cula con ejemplos de im√°genes por categor√≠a.
    """
    # Agrupar por categor√≠a
    grouped = {}
    for category, img_bytes in binary_images:
        grouped.setdefault(category, []).append(img_bytes)

    # Calcular n√∫mero de categor√≠as
    num_categories = len(grouped)
    print(f"üì∏ Mostrando ejemplos de {num_categories} categor√≠as (m√°x {examples_per_category} por categor√≠a)\n")

    # Mostrar cada categor√≠a
    for category, imgs in grouped.items():
        plt.figure(figsize=(12, 2))
        plt.suptitle(category, fontsize=14)

        # Seleccionar ejemplos aleatorios
        sample_imgs = random.sample(imgs, min(examples_per_category, len(imgs)))

        for i, img_bytes in enumerate(sample_imgs):
            with Image.open(io.BytesIO(img_bytes)) as img:
                img = img.convert("RGB").resize(size)
                plt.subplot(1, examples_per_category, i + 1)
                plt.imshow(img)
                plt.axis("off")

        plt.show()

show_examples_per_category(binary_cards, examples_per_category=6)

import pickle

with open("/content/drive/MyDrive/binary_cards.pkl", "wb") as f:
    pickle.dump(binary_cards, f)

from google.colab import drive
import pickle

# Montar Google Drive
drive.mount('/content/drive')

# Cargar el objeto pickle
file_path = "/content/drive/MyDrive/binary_cards.pkl"
with open(file_path, "rb") as f:
    binary_cards = pickle.load(f)

print(f"‚úÖ Recuperadas {len(binary_cards)} im√°genes y etiquetas.")

import numpy as np
from sklearn.model_selection import train_test_split

def split_dataset(binary_cards, test_size=0.1, val_size=0.1, random_state=42):
    """
    Divide los datos en conjuntos de entrenamiento, validaci√≥n y test.

    binary_cards: lista de tuplas (categoria, imagen_binaria)
    test_size: proporci√≥n del conjunto de test
    val_size: proporci√≥n del conjunto de validaci√≥n
    """
    # Convertir a arrays numpy
    categories, images = zip(*binary_cards)
    categories = np.array(categories)
    images = np.array(images)

    # Dividir en train y test primero
    X_train, X_temp, y_train, y_temp = train_test_split(
        images, categories, test_size=test_size + val_size, stratify=categories, random_state=random_state
    )

    # De lo que qued√≥, separar validaci√≥n y test
    relative_val_size = val_size / (test_size + val_size)
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=relative_val_size, stratify=y_temp, random_state=random_state
    )

    print(f"üß† Train: {len(X_train)} | ‚úÖ Val: {len(X_val)} | üß™ Test: {len(X_test)}")
    return (X_train, y_train), (X_val, y_val), (X_test, y_test)

(train_X, train_y), (val_X, val_y), (test_X, test_y) = split_dataset(binary_cards, test_size=0.1, val_size=0.1)

print("Dimensiones imagenes de entrenamiento: ", train_X.shape)
print("Dimensiones etiquetas de entrenamiento: ", train_y.shape)

print("Dimensiones imagenes de validaci√≥n: ", val_X.shape)
print("Dimensiones etiquetas de validaci√≥n: ", val_y.shape)

print("Dimensiones imagenes de test: ", test_X.shape)
print("Dimensiones etiquetas de test: ", test_y.shape)

from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical

# Codificar etiquetas a enteros
le = LabelEncoder()
train_y_enc = le.fit_transform(train_y)
val_y_enc = le.transform(val_y)
test_y_enc = le.transform(test_y)

# Convertir a one-hot (para clasificaci√≥n multiclase)
num_classes = len(le.classes_)
train_y_cat = to_categorical(train_y_enc, num_classes)
val_y_cat = to_categorical(val_y_enc, num_classes)
test_y_cat = to_categorical(test_y_enc, num_classes)

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import io
from PIL import Image

def create_generators(train_X, train_y, val_X, val_y, test_X, test_y, batch_size=32):
    # Convertir binarios a arrays de imagen (si no lo hiciste antes)
    def decode_images(X):
        imgs = []
        for img_bytes in X:
            img = Image.open(io.BytesIO(img_bytes)).convert('RGB')
            imgs.append(np.array(img))
        return np.array(imgs)

    X_train = decode_images(train_X)
    X_val = decode_images(val_X)
    X_test = decode_images(test_X)

    # Normalizaci√≥n y aumentaci√≥n solo para entrenamiento
    train_datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=15,
        width_shift_range=0.1,
        height_shift_range=0.1,
        shear_range=0.1,
        zoom_range=0.1,
        horizontal_flip=True,
        fill_mode='nearest'
    )

    test_datagen = ImageDataGenerator(rescale=1./255)

    # Generadores
    train_gen = train_datagen.flow(X_train, train_y, batch_size=batch_size)
    val_gen = test_datagen.flow(X_val, val_y, batch_size=batch_size)
    test_gen = test_datagen.flow(X_test, test_y, batch_size=batch_size, shuffle=False)

    return train_gen, val_gen, test_gen

train_gen, val_gen, test_gen = create_generators(train_X, train_y_cat, val_X, val_y_cat, test_X, test_y_cat)

from tensorflow.keras.applications import MobileNetV2
import tensorflow as tf

base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

x = base_model.output

"""  reducir dimensiones de salida """
x = tf.keras.layers.GlobalAveragePooling2D()(x)

""" capa densa entrenable """
x = tf.keras.layers.Dense(256, activation='relu')(x)

predictions = tf.keras.layers.Dense(6, activation='softmax')(x)

model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)

for layer in base_model.layers:
    layer.trainable = False

model.summary()

"""compile model"""
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

"""create early stopping callback"""
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)

""" train model"""
history = model.fit(train_gen, epochs=100, validation_data=val_gen, callbacks=[early_stopping])

import matplotlib.pyplot as plt

"""" Grafica de perdida y accurady"""
plt.figure(figsize=[15,8])

plt.subplot(1,2,1)
plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='val')
plt.legend()
plt.title('Loss')

"""" Grafica de precision"""
plt.subplot(1,2,2)
plt.plot(history.history['accuracy'], label='train')
plt.plot(history.history['val_accuracy'], label='val')
plt.legend()
plt.title('Accuracy')

plt.show()

from google.colab import drive
from keras.saving import save_model

# Montar Google Drive
#drive.mount('/content/drive')

# Save model
#model.save("/content/drive/model_graphic_cards_transfer_learning.h5")
save_model(model, "/content/model_graphic_cards_transfer_learning.keras")

!cp -r /content/model_graphic_cards_transfer_learning.keras /content/drive/MyDrive/

model.save("/content/drive/MyDrive/model_graphic_cards_transfer_learning.h5")

_, test_accuracy = model.evaluate(test_gen)
print(f"Test accuracy: {test_accuracy}")